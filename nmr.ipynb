{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMR = \"nmr-87\"\n",
    "VERSION = \"10\"\n",
    "CONFIG_PATH = \"./config/numerai/%s-%s.json\"%(NMR, VERSION)\n",
    "DATA_PATH = \"./data/numerai\"\n",
    "\n",
    "# sklearn model config dict\n",
    "parameters = [\n",
    "    {\n",
    "        \"classifier\": \"mlp\",\n",
    "        \"grid\": {\n",
    "                \"classifier__activation\": [\n",
    "                    \"relu\"\n",
    "                ],\n",
    "                \"classifier__hidden_layer_sizes\": [\n",
    "                    [\n",
    "                        30,\n",
    "                        20,\n",
    "                        10\n",
    "                    ]\n",
    "                ],\n",
    "                \"classifier__solver\": [\n",
    "                    \"adam\"\n",
    "                ]\n",
    "            }\n",
    "    }\n",
    "]\n",
    "\n",
    "conf = {\n",
    "    \"name\": NMR,\n",
    "    \"data\": DATA_PATH,\n",
    "    \"training\": {\n",
    "        \"parameters\": parameters\n",
    "    },\n",
    "    \"evaluate\": {\n",
    "        \"models\": [\"mlp\"]\n",
    "    },\n",
    "    \"labels\": \"target\",\n",
    "    \"model_path\": \"./models/\",\n",
    "    \"model_no\": VERSION\n",
    "}\n",
    "\n",
    "# write the config dict to file\n",
    "with open(CONFIG_PATH, 'w') as f:\n",
    "    json.dump(conf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-24T13:05:36 INFO numerapi: downloading current dataset...\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://api.numer.ai/competitions/current/dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-dcc975b4102c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# download current dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdl_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_current_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munzip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Download succeeded: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_succeeded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dhruv/Github/pipeline/numerapi.py\u001b[0m in \u001b[0;36mdownload_current_dataset\u001b[0;34m(self, dest_path, conf, unzip)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# get data for current dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mdataset_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mdataset_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# create parent folder if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dhruv/anaconda/lib/python3.5/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api.numer.ai/competitions/current/dataset"
     ]
    }
   ],
   "source": [
    "''' Download latest NMR Dataset\n",
    "\n",
    "'''\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "napi = NumerAPI(verbosity=\"info\")\n",
    "        \n",
    "# set up directory to download dataset\n",
    "download_path = \"./%s/%s\" % (DATA_PATH, NMR)\n",
    "if not os.path.isdir(download_path):\n",
    "    os.mkdir(download_path)\n",
    "\n",
    "# download current dataset\n",
    "dl_succeeded = napi.download_current_dataset(dest_path=DATA_PATH, conf=conf, unzip=True)\n",
    "print(\"Download succeeded: \" + str(dl_succeeded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = \"pca\"\n",
    "\n",
    "#flag = \"numerai_tournament_data.csv\"\n",
    "flag = \"numerai_training_data.csv\"\n",
    "output_file = \"%s/%s-%s-%s.csv\"%(DATA_PATH, NMR, flag, transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393613, 11)\n"
     ]
    }
   ],
   "source": [
    "# Perform dimensionality reduction on dataset\n",
    "import pandas as pd\n",
    "\n",
    "from utils import utils\n",
    "from preprocess import preprocess\n",
    "\n",
    "transformer = preprocess.get_transformation(transformation, n_components=10)\n",
    "\n",
    "path = \"%s/%s\" % (conf.get(\"data\"), flag)\n",
    "\n",
    "data = utils.load_data(path)\n",
    "features = utils.get_features(data)\n",
    "output = pd.DataFrame(transformer.fit_transform(features))\n",
    "output['target'] = data['target']\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "#output.to_csv(output_file, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run id nmr-87-10-mlp\n",
      "Starting Grid Search\n"
     ]
    }
   ],
   "source": [
    "# Train sklearn models\n",
    "import nmr_train\n",
    "\n",
    "#training_filename = \"%s-%s-%s.csv\"%(NMR, flag, transformation)\n",
    "training_filename = \"numerai_training_data.csv\"\n",
    "nmr_train.train(conf, training_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = conf.get(\"evaluate\").get(\"models\")\n",
    "estimators = [utils.load_model(conf, model) for model in models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_file = \"numerai_tournament_data.csv\"\n",
    "path = \"%s/%s\"%(conf.get(\"data\"), tournament_file)\n",
    "data = utils.load_data(path)\n",
    "X = utils.get_features(data)\n",
    "\n",
    "# Evaluate single model\n",
    "estimator = estimators[0]\n",
    "probabilities = estimator.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "predictions = pd.DataFrame()\n",
    "predictions['id'] = data['id']\n",
    "predictions['probability'] = probabilities[:,1]\n",
    "\n",
    "pred_path = \"%s/%s-%s.csv\" % (\"./predictions\", conf.get(\"name\"), conf.get(\"model_no\"))\n",
    "predictions.to_csv(pred_path,\n",
    "                    sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
